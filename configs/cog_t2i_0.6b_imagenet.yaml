vae:
    module: cogvideo.models.autoencoders
    class_name: AutoencoderKL
    params:
        pretrained: /storage/qiguojunLab/fangxueji/Models/sdxl-vae
tokenizer:
    module: transformers
    class_name: T5Tokenizer
    params:
        pretrained: /storage/qiguojunLab/qiguojun/home/Models/google/mt5-base/
text_encoder:
    module: transformers
    class_name: T5EncoderModel
    params:
        pretrained: /storage/qiguojunLab/qiguojun/home/Models/google/mt5-base/
transformer:
    module: cogvideo.models
    class_name: CogVideoXTransformer3DModel
    params:
        activation_fn:                      gelu-approximate
        attention_bias:                     true
        attention_head_dim:                 48
        dropout:                            0.0
        flip_sin_to_cos:                    true
        freq_shift:                         0
        in_channels:                        4
        max_text_seq_length:                226
        norm_elementwise_affine:            true
        norm_eps:                           0.00001
        num_attention_heads:                24  # 30
        num_layers:                         26  # 30
        out_channels:                       4
        patch_size:                         2
        sample_frames:                      1
        sample_height:                      32
        sample_width:                       32
        spatial_interpolation_scale:        1.875
        temporal_compression_ratio:         4
        temporal_interpolation_scale:       1.0
        text_embed_dim:                     768
        time_embed_dim:                     512
        timestep_activation_fn:             silu
        use_learned_positional_embeddings:  false
        use_rotary_positional_embeddings:   true
scheduler:
    module: diffusers
    class_name: FlowMatchEulerDiscreteScheduler
    params:
        shift:                              1.0
pipeline:
    module: cogvideo.pipelines
    class_name: CogVideoXPipeline
loss_function:
    module: training.losses
    class_name: CogFMLoss
    params: {}
    
optimizer:
    module: torch.optim
    class_name: AdamW
    params:
        lr:                         0.0001
        betas:                      [0.9, 0.999]
        weight_decay:               0.01
        eps:                        0.00000001
lr_scheduler:
    name:                           constant_with_warmup
    lr_warmup_steps:                1000

dataloader:
    module: training.dataset
    class_name: MdsDataLoader
    params:
        batch_size:                 192
        num_workers:                16
        image_folder:               null
        local_train_dir:            /storage/qiguojunLab/qiguojun/home/Datasets/imagenet.int8/
        cfg:                        0.1
        model_max_length:           226
        
training_args:
    team_name:                      maple-video
    exp_name:                       cog_t2i_0.6b_imagenet
    output_dir:                     ./outputs/
    logging_dir:                    logs
    grad_acc:                       1
    mixed_precision:                bf16
    report_to:                      wandb
    ema_decay:                      0.9999
    ema_start_step:                 0
    max_train_steps:                200_000
    resume_from_checkpoint:         latest
    checkpointing_steps:            1000
    checkpoints_total_limit:        100
    gradient_checkpointing:         true
    max_grad_norm:                  10.0
