vae:
    module: cogvideo.models
    class_name: AutoencoderKLCogVideoX
    params:
        pretrained: /storage/qiguojunLab/qiguojun/home/Models/THUDM/CogVideoX-2b/vae
tokenizer:
    module: transformers
    class_name: T5Tokenizer
    params:
        pretrained: /storage/qiguojunLab/qiguojun/home/Models/google/mt5-base/
text_encoder:
    module: transformers
    class_name: T5EncoderModel
    params:
        pretrained: /storage/qiguojunLab/qiguojun/home/Models/google/mt5-base/
transformer:
    module: momo.models
    class_name: MomoTransformer
    params:
        attention_head_dim:             48
        dropout:                        0.0
        flip_sin_to_cos:                true
        freq_shift:                     0
        latent_space_channel:           16
        max_height:                     512
        max_text_seq_length:            226
        max_width:                      512
        norm_elementwise_affine:        true
        norm_eps:                       0.00001
        num_attention_heads:            21
        patch_bias:                     true
        patch_size:                     2
        patch_size_t:                   1
        sample_frames:                  1
        sample_height:                  256
        sample_width:                   256
        spatial_interpolation_scale:    8
        spatial_num_frames:             1
        spatial_num_layers:             24
        temporal_compression_ratio:     4
        temporal_interpolation_scale:   1
        temporal_num_layers:            16
        text_embed_dim:                 768
        time_embed_dim:                 512
        timestep_activation_fn:             "silu"
        use_learned_positional_embeddings:  false
        use_rotary_positional_embeddings:   true

scheduler:
    module: diffusers
    class_name: FlowMatchEulerDiscreteScheduler
    params:
        shift:                              1.0
pipeline:
    module: momo.pipelines
    class_name: MomoPipeline
loss_function:
    module: training.losses
    class_name: MomoVidFMLossSF
    params:
        use_degrade:                false
        degrade_scheduler:          cosine
        num_frames:                 8
        mean:                       0.5 # -2
        std:                        0.5
    
optimizer:
    module: torch.optim
    class_name: AdamW
    params:
        lr:                         0.0001
        betas:                      [0.9, 0.999]
        weight_decay:               0.01
        eps:                        0.00000001
lr_scheduler:
    name:                           constant_with_warmup
    lr_warmup_steps:                1000

dataloader:
    module: training.dataset
    class_name: VideoDataLoader
    params:
        cfg:                        0.1
        max_text_seq_length:        226
        # vid_pkl_path:               /storage/qiguojunLab/fangxueji/Projects/video_base/dataset/phase3_t2v_v2_webvid_hd_only/webvid-6.6m.pkl
        # vid_pkl_path:               /storage/qiguojunLab/fangxueji/Projects/video_base/dataset/phase4_t2v_v1_hd_finetune/openvid-1m.pkl
        vid_pkl_path:               datasets/ucf-101/train.pkl
        vid_folder:                 '/'
        target_path_keys:           path
        target_prompt_key:          caption
        max_height:                 256
        max_width:                  256
        num_frames:                 29
        sample_rate:                4
        batch_size:                 64
        num_workers:                16
        
training_args:
    team_name:                      maple-video
    exp_name:                       momo_0.6b_t2v_ucf_sf
    output_dir:                     ./outputs/
    logging_dir:                    logs
    grad_acc:                       1
    mixed_precision:                bf16
    report_to:                      wandb
    ema_decay:                      0.999
    ema_start_step:                 0
    max_train_steps:                50_000
    resume_from_checkpoint:         null # latest
    resume_model:                   outputs/momo_0.6b_t2v_ucf_sf/checkpoint-1500/model/diffusion_pytorch_model.safetensors
    resume_ema_model:               outputs/momo_0.6b_t2v_ucf_sf/checkpoint-1500/model_ema/diffusion_pytorch_model.safetensors
    checkpointing_steps:            500
    checkpoints_total_limit:        100
    gradient_checkpointing:         true
    max_grad_norm:                  10.0
